{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tjtyler/MachLearn_MultiLayerPerceptron_BackProp/blob/main/lab_2_backprop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVL7_bgmIAPR"
      },
      "source": [
        "# Backpropagation Lab\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Debug Data = $\\begin{bmatrix} -0.4 & 0.3 & 1 \\\\ -0.3 & 0.8 & 1\\\\ \n",
        "-0.2 & 0.3 & 1\\\\ -0.1 & 0.9 & 1\\\\ -0.1 & 0.1 & 0\\\\ 0.0 & -0.2 & 0\\\\ 0.1 & 0.2 & 0\\\\ 0.2 & -0.2 & 0\\end{bmatrix}$\n",
        "\n",
        "$net_{node} = w_{layer} \\cdot x$\n",
        "\n",
        "$z_{node} = \\frac{1}{1+e^{net}}$\n",
        "\n",
        "$\\delta_{w_{pq}} = $"
      ],
      "metadata": {
        "id": "xnocHDpkTCv7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6ZbYjZZZ_yLV"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWMWTgeiJWJ4",
        "outputId": "5e5f8b5d-6c80-4856-88b0-83409fa9846d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCcEPx5VIORj"
      },
      "source": [
        "## 1. (40%) Correctly implement and submit your own code for the backpropagation algorithm. \n",
        "\n",
        "## Code requirements \n",
        "- Ability to create a network structure with at least one hidden layer and an arbitrary number of nodes.\n",
        "- Random weight initialization with small random weights with mean of 0 and a variance of 1.\n",
        "- Use Stochastic/On-line training updates: Iterate and update weights after each training instance (i.e., do not attempt batch updates)\n",
        "- Implement a validation set based stopping criterion.\n",
        "- Shuffle training set at each epoch.\n",
        "- Option to include a momentum term\n",
        "\n",
        "Use your Backpropagation algorithm to solve the Debug data. We provide you with several parameters, and you should be able to replicate our results every time. When you are confident it is correct, run your script on the Evaluation data with the same parameters, and print your final weights."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(net):\n",
        "  \"\"\"The sigmoid function.\"\"\"\n",
        "  return 1.0/(1.0+np.exp(-net))"
      ],
      "metadata": {
        "id": "USpniuxk9tDx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from os import get_terminal_size\n",
        "from typing_extensions import ParamSpecKwargs\n",
        "class MLP(BaseEstimator,ClassifierMixin):\n",
        "\n",
        "    def __init__(self, arch, epochs, lr=.1, momentum=0, shuffle=True,):\n",
        "        \"\"\" Initialize class with chosen hyperparameters.\n",
        "\n",
        "        Args:\n",
        "            arch: a list of nodes at each layer, including the inputs and outputs, but not including bias nodes\n",
        "            epochs: the number of epochs to run the fit function \n",
        "            lr (float): A learning rate / step size.\n",
        "            shuffle(boolean): Whether to shuffle the training data each epoch. DO NOT SHUFFLE for evaluation / debug datasets.\n",
        "            momentum(float): The momentum coefficent \n",
        "        Example:\n",
        "            mlp = MLP(lr=.2,momentum=.5,shuffle=False,hidden_layer_widths = [3,3]),  <--- this will create a model with two hidden layers, both 3 nodes wide\n",
        "        \"\"\"\n",
        "        self.arch = arch # [2,2,1] means 2 inputs, 1 hidden layer with 2 nodes, and 1 output\n",
        "        self.epochs = epochs\n",
        "        self.lr = lr\n",
        "        self.momentum = momentum\n",
        "        self.shuffle = shuffle\n",
        "        self.layer_wts =[] # list of numpy matrices or vectors with the first element being the weights between the inputs and the first hidden layer, the second element being the weights between the first and second hidden layers, etc.\n",
        "        self.layer_prev_wts = None\n",
        "        self.accuracies = []\n",
        "\n",
        "    def fit(self, X, y, epochs_no_change=11, tol=0.01, default_wts=False, initial_wts=0):\n",
        "        \"\"\" Fit the data; run the algorithm and adjust the weights to find a good solution\n",
        "\n",
        "        Args:\n",
        "            X (array-like): A 2D numpy array with the training data, excluding targets\n",
        "            y (array-like): A 2D numpy array with the training targets\n",
        "        Optional Args (Args we think will make your life easier):\n",
        "            initial_weights (array-like): allows the user to provide initial weights\n",
        "        Returns:\n",
        "            self: this allows this to be chained, e.g. model.fit(X,y).predict(X_test)\n",
        "\n",
        "        \"\"\"\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "        v_sigmoid = np.vectorize(sigmoid) # this converts the sigmoid function to a function that that can take a vector and apply the function to it\n",
        "\n",
        "        if default_wts:\n",
        "          self.layer_wts = self.initialize_weights()\n",
        "        else:\n",
        "          self.layer_wts = self.initialize_weights_with_value(initial_wts)\n",
        "        delta_wts = self.layer_wts.copy()\n",
        "        print(\"INITIAL WEIGHTS:\\n\", self.layer_wts)\n",
        "\n",
        "        #--------------weight initialization working correctly------------------\n",
        "\n",
        "        self.cur_epoch = 0\n",
        "        num_epoch_no_change = 0\n",
        "        last_score = None\n",
        "        while self.cur_epoch < self.epochs and num_epoch_no_change < epochs_no_change:\n",
        "          X_bias = None # this will be the input matrix with a column of 1s concatenated for the bias\n",
        "          if self.shuffle:\n",
        "            self._shuffle_data(self.X, self.y)\n",
        "          bias = np.ones((self.X.shape[0],1)) # bias vector of ones\n",
        "          X_bias = np.concatenate((self.X,bias), axis=1) # set X = X_shuffled with bias concatenated\n",
        "          #---------------------------------------------------------------------\n",
        "          for row in range(X_bias.shape[0]):\n",
        "            Zs_by_layer = []\n",
        "            nets_by_layer = []\n",
        "            node_errors_by_layer = []\n",
        "            delta_wts = self.layer_wts.copy()\n",
        "            # FORWARD-FEED\n",
        "            print('\\n\\nFORWARD-FEED:')\n",
        "            print('Training Instance data:\\n', X_bias[row])\n",
        "            for lay in range(0, len(self.layer_wts)):\n",
        "              if lay == 0:\n",
        "                net = np.matmul(X_bias[row], self.layer_wts[lay])\n",
        "                nets_by_layer.append(net)\n",
        "                Zs_lay = v_sigmoid(net)\n",
        "                Zs_by_layer.append(Zs_lay)\n",
        "              else:\n",
        "                Zs_by_layer[lay-1] = np.insert(Zs_by_layer[lay-1],Zs_by_layer[lay-1].shape[0],[1]) # add a one to the Zs_by_layer for the bias\n",
        "                net = np.matmul(Zs_by_layer[lay-1], self.layer_wts[lay])\n",
        "                nets_by_layer.append(net)\n",
        "                Zs_lay = v_sigmoid(net)\n",
        "                Zs_by_layer.append(Zs_lay) \n",
        "                print(f'Zs:\\n', Zs_by_layer) \n",
        "\n",
        "            # BACK PROPAGATE\n",
        "            print('\\nBACK-PROPAGATE:')\n",
        "            target_vec = self.get_target_vec(row)\n",
        "            target_vec = target_vec.flatten()\n",
        "            for lay_indx in reversed(range(0, len(self.layer_wts))):\n",
        "              i = 0 # need this to access the node_erros from previous layer to calculate next layer (working backwards)\n",
        "              if lay_indx == (len(self.layer_wts) - 1): \n",
        "                print('COMPUTING ERROR AT OUTPUT NODES')\n",
        "                # COMPUTE THE ERROR AT THE OUTPUT NODES\n",
        "                  # (target_j - z_j)*z_j*(1 - z_j)\n",
        "                OutNodes_error = (target_vec - Zs_by_layer[lay_indx])*Zs_by_layer[lay_indx]*(np.ones(Zs_by_layer[lay_indx].shape) - Zs_by_layer[lay_indx])\n",
        "                # ADD THE ERROR AT OUTPUT NODES VECTOR TO node_errors_by_layer\n",
        "                node_errors_by_layer.append(OutNodes_error)\n",
        "\n",
        "              else:\n",
        "                # CALCULATE CHANGE IN WEIGHTS\n",
        "                print(f'CHANGE IN WEIGHTS BETWEEN LAYER {lay_indx+1} AND LAYER {lay_indx+ 2}')\n",
        "                  # delta_wts_ij = learning_rate * error_at_node_j * z_i\n",
        "                lr_vec_shape = node_errors_by_layer[i-1].shape\n",
        "                lr_vec = np.full(lr_vec_shape, self.lr) \n",
        "                Zs = Zs_by_layer[lay_indx]\n",
        "                Zs = Zs.reshape(Zs.shape[0],1) # make Zs a column vector\n",
        "                errors_at_nodes = node_errors_by_layer[i-1]\n",
        "                delta_wts[lay_indx+1] = Zs * lr_vec * errors_at_nodes \n",
        "\n",
        "                # COMPUTE THE ERROR AT HIDDEN LAYERS\n",
        "                print('COMPUTING ERROR AT HIDDEN LAYER NODES')\n",
        "                  # error_node_j = Sum(error_node_k * wt_j->k)*f_prime_net_j\n",
        "                delta_dot_w = np.matmul(self.layer_wts[lay_indx+1],node_errors_by_layer[i-1])\n",
        "                delta_dot_w = delta_dot_w[:-1] # exclude the bias node\n",
        "                  # f_prime_net = z_j*(1 - z_j)\n",
        "                f_prime_net = (Zs_by_layer[lay_indx]) * (np.ones( (Zs_by_layer[lay_indx].shape[0]) ) - Zs_by_layer[lay_indx]) \n",
        "                f_prime_net = f_prime_net[:-1] # exclude the bias node\n",
        "                # ADD THE ERROR AT HIDDEN LAYER NODES VECTOR TO node_errors_by_layer\n",
        "                node_errors_by_layer.append(np.multiply(delta_dot_w ,f_prime_net))\n",
        "\n",
        "                if lay_indx == 0:\n",
        "                  lr_vec_shape = node_errors_by_layer[-1].shape\n",
        "                  lr_vec = np.full(lr_vec_shape, self.lr) \n",
        "                  inputs = X_bias[row]\n",
        "                  inputs = inputs.reshape(inputs.shape[0],1) # make inputs a column vector\n",
        "                  errors_at_nodes = node_errors_by_layer[-1]\n",
        "                  delta_wts[lay_indx] = inputs * lr_vec * errors_at_nodes       \n",
        "              i += 1\n",
        "\n",
        "            node_errors_by_layer.reverse()\n",
        "            print('PREVIOUS WEIGHTS\\n', self.layer_wts) \n",
        "            for i in range(len(self.layer_wts)):\n",
        "              self.layer_wts[i] = self.layer_wts[i] + delta_wts[i]\n",
        "            print('NODE ERRORS BY LAYER\\n',node_errors_by_layer)\n",
        "            print('CHANGE IN WEIGHTS\\n', delta_wts)\n",
        "            print('NEW UPDATED WEIGHTS\\n', self.layer_wts)\n",
        "          #---------------\n",
        "\n",
        "          # if self.cur_epoch == 0:\n",
        "          #   last_score = self.score(self.X,self.y)\n",
        "          #   self.accuracies.append(last_score)\n",
        "          # elif self.cur_epoch > 0:\n",
        "          #   cur_score = self.score(self.X,self.y)\n",
        "          #   if ((cur_score - last_score)**2)**(1/2) < tol:\n",
        "          #     num_epoch_no_change +=1\n",
        "          #   else:\n",
        "          #     num_epoch_no_change = 0\n",
        "          #   last_score = cur_score\n",
        "          #   self.accuracies.append(last_score)\n",
        "          \n",
        "          self.cur_epoch +=1\n",
        "        \n",
        "        return self\n",
        "\n",
        "    def get_target_vec(self,row):\n",
        "      # THIS RETURNS A COLUMN VECTOR\n",
        "      target_value = int(self.y[row][0])\n",
        "      target_vector = np.zeros(shape=(self.arch[-1],1))\n",
        "      target_vector[target_value][0] = 1\n",
        "      return target_vector\n",
        "      \n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\" \n",
        "            Predict all classes for a dataset X\n",
        "        Args:\n",
        "            X (array-like): A 2D numpy array with the training data, excluding \n",
        "            targets\n",
        "        Returns:\n",
        "            array, shape (n_samples,)\n",
        "                Predicted target values per element in X.\n",
        "        \"\"\"\n",
        "        # bias = np.ones((X.shape[0],1)) # bias vector of ones\n",
        "        # X_bias = np.concatenate((X,bias), axis=1) # set X = X_shuffled with bias concatenated\n",
        "        # predictions = np.zeros([X.shape[0],1])\n",
        "        # for row in range(0, X.shape[0]):\n",
        "        #   net = self.calcNet(X_bias, row)\n",
        "        #   output = self.output(net)\n",
        "        #   predictions[row][0] = output\n",
        "        # return predictions\n",
        "        return 0\n",
        "\n",
        "    def initialize_weights_with_value(self, val):\n",
        "      # if self.arch = [2,3,2] then the lay1_wts have a shape of (3,3) and lay2_wts a shape of (4,2)\n",
        "        for i in range(0, len(self.arch) - 1):\n",
        "          self.layer_wts.append(np.full((self.arch[i] + 1, self.arch[i+1]),val))\n",
        "        return self.layer_wts\n",
        "\n",
        "    def initialize_weights(self):\n",
        "        \"\"\" Initialize weights for perceptron. Don't forget the bias!\n",
        "        Returns:\n",
        "        \"\"\"\n",
        "        # if self.arch = [2,3,2] then the lay1_wts have a shape of (3,3) and lay2_wts a shape of (4,2)\n",
        "        for i in range(0, len(self.arch) - 1):\n",
        "          self.layer_wts.append(np.random.randn(self.arch[i] + 1, self.arch[i+1]))\n",
        "        return self.layer_wts\n",
        "\n",
        "    # def initialize_zero_weights(self):\n",
        "    #     \"\"\" Initialize weights for perceptron. Don't forget the bias!\n",
        "\n",
        "    #     Returns:\n",
        "\n",
        "    #     \"\"\"\n",
        "    #     # if self.arch = [2,3,2] then the lay1_wts have a shape of (3,3) and lay2_wts a shape of (4,2)\n",
        "    #     for i in range(0, len(self.arch) - 1):\n",
        "    #       self.layer_wts.append(np.zeros((self.arch[i] + 1, self.arch[i+1])))\n",
        "    #     return self.layer_wts\n",
        "\n",
        "    def score(self, X, y):\n",
        "        \"\"\" \n",
        "            Return accuracy of model on a given dataset. Must implement own \n",
        "            score function.\n",
        "        Args:\n",
        "            X (array-like): A 2D numpy array with data, excluding targets\n",
        "            y (array-like): A 2D numpy array with targets\n",
        "        Returns:\n",
        "            score : float\n",
        "                Mean accuracy of self.predict(X) wrt. y.\n",
        "        \"\"\"\n",
        "        self._shuffle_data(X,y)\n",
        "        predictions = self.predict(X)\n",
        "        correct = 0\n",
        "        total = y.shape[0]\n",
        "        for i in range(0, y.shape[0]):\n",
        "          if predictions[i][0] == y[i][0]:\n",
        "            correct += 1\n",
        "        return correct/total\n",
        "\n",
        "\n",
        "    def _shuffle_data(self, X, y):\n",
        "        \"\"\" Shuffle the data! This _ prefix suggests that this method should only be called internally.\n",
        "            It might be easier to concatenate X & y and shuffle a single 2D array, rather than\n",
        "             shuffling X and y exactly the same way, independently.\n",
        "        \"\"\"\n",
        "        single_arr = np.concatenate((X,y), axis=1) # concatenate X and y into a single array\n",
        "        np.random.shuffle(single_arr) # shuffle the rows of the concatenated X-y array\n",
        "        cutoff = single_arr.shape[1] - 1 # the point to split the X and y arrays after shuffling\n",
        "        X = single_arr[:,:cutoff] # the shuffled X array\n",
        "        y = single_arr[:,cutoff:] # the shuffled y array\n",
        "\n",
        "    ### Not required by sk-learn but required by us for grading. Returns the weights.\n",
        "    def get_weights(self):\n",
        "        return self.init_layer_wts\n"
      ],
      "metadata": {
        "id": "V9fo9TKBXiwf"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KibCIXIThpbE"
      },
      "source": [
        "## 1.1 \n",
        "\n",
        "Debug your model using the following parameters:\n",
        "\n",
        "Learning Rate = 0.1\\\n",
        "Momentum = 0.5\\\n",
        "Deterministic = 10 [This means run it 10 epochs and should be the same everytime you run it]\\\n",
        "Shuffle = False\\\n",
        "Validation size = 0\\\n",
        "Initial Weights = All zeros\\\n",
        "Hidden Layer Widths = [4]\n",
        "\n",
        "---\n",
        "\n",
        "### 1.1.1 Debug \n",
        "\n",
        "Debug your model by running it on the [Debug Dataset](https://byu.instructure.com/courses/14142/files?preview=4421290)\n",
        "\n",
        "\n",
        "Expected Results for Binary Classification (i.e. 1 output node): [debug_bp_0.csv](https://byu.instructure.com/courses/14142/files?preview=4537323) \n",
        "\n",
        "$$ \\text{Layer 1} = \\begin{bmatrix} -8.81779797\\text{e}-05 & -8.81779797\\text{e}-05 & -8.81779797\\text{e}-05 & -8.81779797\\text{e}-05 \\\\ 7.82757731\\text{e}-04 & 7.82757731\\text{e}-04 & 7.82757731\\text{e}-04 & 7.82757731\\text{e}-04 \\\\ -3.94353645\\text{e}-03 & -3.94353645\\text{e}-03 & -3.94353645\\text{e}-03 & -3.94353645\\text{e}-03 \\end{bmatrix}$$\n",
        "                                             \n",
        "$$ \\text{Layer 2} = \\begin{bmatrix} -0.01060888 \\\\ -0.01060888 \\\\ -0.01060888 \\\\ -0.01060888 \\\\ -0.02145495 \\end{bmatrix}$$\n",
        "\n",
        "(The weights do not need to be in this order or shape.)\n",
        "\n",
        "Expected Results for One Hot Vector Classification (i.e. 2 output nodes): [debug_bp_2outs.csv](https://byu.instructure.com/courses/14142/files?preview=4537340) \n",
        "\n",
        "$$ \\text{Layer 1} = \\begin{bmatrix} -0.00018149 & -0.00018149 & -0.00018149 & -0.00018149 \\\\ 0.00157468 & 0.00157468 & 0.00157468 & 0.00157468 \\\\ -0.00788218 & -0.00788218 & -0.00788218 & -0.00788218 \\end{bmatrix}$$\n",
        "                          \n",
        "$$ \\text{Layer 2} = \\begin{bmatrix} 0.01050642 & -0.01050642 \\\\ 0.01050642 & -0.01050642 \\\\ 0.01050642 & -0.01050642 \\\\ 0.01050642 & -0.01050642 \\\\ 0.02148778 & -0.02148778 \\end{bmatrix}$$\n",
        "\n",
        "(The weights do not need to be in this order or shape.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "KgAyy82gixIF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3febf4ab-76cf-4782-8ba7-e2c56915590a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INITIAL WEIGHTS:\n",
            " [array([[0, 0, 0, 0],\n",
            "       [0, 0, 0, 0],\n",
            "       [0, 0, 0, 0]]), array([[0, 0],\n",
            "       [0, 0],\n",
            "       [0, 0],\n",
            "       [0, 0],\n",
            "       [0, 0]])]\n",
            "\n",
            "\n",
            "FORWARD-FEED:\n",
            "Training Instance data:\n",
            " [-0.4  0.3  1. ]\n",
            "Zs:\n",
            " [array([0.5, 0.5, 0.5, 0.5, 1. ]), array([0.5, 0.5])]\n",
            "\n",
            "BACK-PROPAGATE:\n",
            "COMPUTING ERROR AT OUTPUT NODES\n",
            "CHANGE IN WEIGHTS BETWEEN LAYER 1 AND LAYER 2\n",
            "COMPUTING ERROR AT HIDDEN LAYER NODES\n",
            "PREVIOUS WEIGHTS\n",
            " [array([[0, 0, 0, 0],\n",
            "       [0, 0, 0, 0],\n",
            "       [0, 0, 0, 0]]), array([[0, 0],\n",
            "       [0, 0],\n",
            "       [0, 0],\n",
            "       [0, 0],\n",
            "       [0, 0]])]\n",
            "NODE ERRORS BY LAYER\n",
            " [array([0., 0., 0., 0.]), array([-0.125,  0.125])]\n",
            "CHANGE IN WEIGHTS\n",
            " [array([[-0., -0., -0., -0.],\n",
            "       [ 0.,  0.,  0.,  0.],\n",
            "       [ 0.,  0.,  0.,  0.]]), array([[-0.00625,  0.00625],\n",
            "       [-0.00625,  0.00625],\n",
            "       [-0.00625,  0.00625],\n",
            "       [-0.00625,  0.00625],\n",
            "       [-0.0125 ,  0.0125 ]])]\n",
            "NEW UPDATED WEIGHTS\n",
            " [array([[0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0.]]), array([[-0.00625,  0.00625],\n",
            "       [-0.00625,  0.00625],\n",
            "       [-0.00625,  0.00625],\n",
            "       [-0.00625,  0.00625],\n",
            "       [-0.0125 ,  0.0125 ]])]\n",
            "\n",
            "\n",
            "FORWARD-FEED:\n",
            "Training Instance data:\n",
            " [-0.3  0.8  1. ]\n",
            "Zs:\n",
            " [array([0.5, 0.5, 0.5, 0.5, 1. ]), array([0.49375033, 0.50624967])]\n",
            "\n",
            "BACK-PROPAGATE:\n",
            "COMPUTING ERROR AT OUTPUT NODES\n",
            "CHANGE IN WEIGHTS BETWEEN LAYER 1 AND LAYER 2\n",
            "COMPUTING ERROR AT HIDDEN LAYER NODES\n",
            "PREVIOUS WEIGHTS\n",
            " [array([[0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0.]]), array([[-0.00625,  0.00625],\n",
            "       [-0.00625,  0.00625],\n",
            "       [-0.00625,  0.00625],\n",
            "       [-0.00625,  0.00625],\n",
            "       [-0.0125 ,  0.0125 ]])]\n",
            "NODE ERRORS BY LAYER\n",
            " [array([0.00038568, 0.00038568, 0.00038568, 0.00038568]), array([-0.1234183,  0.1234183])]\n",
            "CHANGE IN WEIGHTS\n",
            " [array([[-1.15704653e-05, -1.15704653e-05, -1.15704653e-05,\n",
            "        -1.15704653e-05],\n",
            "       [ 3.08545741e-05,  3.08545741e-05,  3.08545741e-05,\n",
            "         3.08545741e-05],\n",
            "       [ 3.85682176e-05,  3.85682176e-05,  3.85682176e-05,\n",
            "         3.85682176e-05]]), array([[-0.00617091,  0.00617091],\n",
            "       [-0.00617091,  0.00617091],\n",
            "       [-0.00617091,  0.00617091],\n",
            "       [-0.00617091,  0.00617091],\n",
            "       [-0.01234183,  0.01234183]])]\n",
            "NEW UPDATED WEIGHTS\n",
            " [array([[-1.15704653e-05, -1.15704653e-05, -1.15704653e-05,\n",
            "        -1.15704653e-05],\n",
            "       [ 3.08545741e-05,  3.08545741e-05,  3.08545741e-05,\n",
            "         3.08545741e-05],\n",
            "       [ 3.85682176e-05,  3.85682176e-05,  3.85682176e-05,\n",
            "         3.85682176e-05]]), array([[-0.01242091,  0.01242091],\n",
            "       [-0.01242091,  0.01242091],\n",
            "       [-0.01242091,  0.01242091],\n",
            "       [-0.01242091,  0.01242091],\n",
            "       [-0.02484183,  0.02484183]])]\n",
            "\n",
            "\n",
            "FORWARD-FEED:\n",
            "Training Instance data:\n",
            " [-0.2  0.3  1. ]\n",
            "Zs:\n",
            " [array([0.50001253, 0.50001253, 0.50001253, 0.50001253, 1.        ]), array([0.48758148, 0.51241852])]\n",
            "\n",
            "BACK-PROPAGATE:\n",
            "COMPUTING ERROR AT OUTPUT NODES\n",
            "CHANGE IN WEIGHTS BETWEEN LAYER 1 AND LAYER 2\n",
            "COMPUTING ERROR AT HIDDEN LAYER NODES\n",
            "PREVIOUS WEIGHTS\n",
            " [array([[-1.15704653e-05, -1.15704653e-05, -1.15704653e-05,\n",
            "        -1.15704653e-05],\n",
            "       [ 3.08545741e-05,  3.08545741e-05,  3.08545741e-05,\n",
            "         3.08545741e-05],\n",
            "       [ 3.85682176e-05,  3.85682176e-05,  3.85682176e-05,\n",
            "         3.85682176e-05]]), array([[-0.01242091,  0.01242091],\n",
            "       [-0.01242091,  0.01242091],\n",
            "       [-0.01242091,  0.01242091],\n",
            "       [-0.01242091,  0.01242091],\n",
            "       [-0.02484183,  0.02484183]])]\n",
            "NODE ERRORS BY LAYER\n",
            " [array([0.00075656, 0.00075656, 0.00075656, 0.00075656]), array([-0.12182018,  0.12182018])]\n",
            "CHANGE IN WEIGHTS\n",
            " [array([[-1.51311803e-05, -1.51311803e-05, -1.51311803e-05,\n",
            "        -1.51311803e-05],\n",
            "       [ 2.26967705e-05,  2.26967705e-05,  2.26967705e-05,\n",
            "         2.26967705e-05],\n",
            "       [ 7.56559016e-05,  7.56559016e-05,  7.56559016e-05,\n",
            "         7.56559016e-05]]), array([[-0.00609116,  0.00609116],\n",
            "       [-0.00609116,  0.00609116],\n",
            "       [-0.00609116,  0.00609116],\n",
            "       [-0.00609116,  0.00609116],\n",
            "       [-0.01218202,  0.01218202]])]\n",
            "NEW UPDATED WEIGHTS\n",
            " [array([[-2.67016456e-05, -2.67016456e-05, -2.67016456e-05,\n",
            "        -2.67016456e-05],\n",
            "       [ 5.35513446e-05,  5.35513446e-05,  5.35513446e-05,\n",
            "         5.35513446e-05],\n",
            "       [ 1.14224119e-04,  1.14224119e-04,  1.14224119e-04,\n",
            "         1.14224119e-04]]), array([[-0.01851208,  0.01851208],\n",
            "       [-0.01851208,  0.01851208],\n",
            "       [-0.01851208,  0.01851208],\n",
            "       [-0.01851208,  0.01851208],\n",
            "       [-0.03702385,  0.03702385]])]\n",
            "\n",
            "\n",
            "FORWARD-FEED:\n",
            "Training Instance data:\n",
            " [-0.1  0.9  1. ]\n",
            "Zs:\n",
            " [array([0.50004127, 0.50004127, 0.50004127, 0.50004127, 1.        ]), array([0.48149569, 0.51850431])]\n",
            "\n",
            "BACK-PROPAGATE:\n",
            "COMPUTING ERROR AT OUTPUT NODES\n",
            "CHANGE IN WEIGHTS BETWEEN LAYER 1 AND LAYER 2\n",
            "COMPUTING ERROR AT HIDDEN LAYER NODES\n",
            "PREVIOUS WEIGHTS\n",
            " [array([[-2.67016456e-05, -2.67016456e-05, -2.67016456e-05,\n",
            "        -2.67016456e-05],\n",
            "       [ 5.35513446e-05,  5.35513446e-05,  5.35513446e-05,\n",
            "         5.35513446e-05],\n",
            "       [ 1.14224119e-04,  1.14224119e-04,  1.14224119e-04,\n",
            "         1.14224119e-04]]), array([[-0.01851208,  0.01851208],\n",
            "       [-0.01851208,  0.01851208],\n",
            "       [-0.01851208,  0.01851208],\n",
            "       [-0.01851208,  0.01851208],\n",
            "       [-0.03702385,  0.03702385]])]\n",
            "NODE ERRORS BY LAYER\n",
            " [array([0.00111266, 0.00111266, 0.00111266, 0.00111266]), array([-0.12020905,  0.12020905])]\n",
            "CHANGE IN WEIGHTS\n",
            " [array([[-1.11265958e-05, -1.11265958e-05, -1.11265958e-05,\n",
            "        -1.11265958e-05],\n",
            "       [ 1.00139363e-04,  1.00139363e-04,  1.00139363e-04,\n",
            "         1.00139363e-04],\n",
            "       [ 1.11265958e-04,  1.11265958e-04,  1.11265958e-04,\n",
            "         1.11265958e-04]]), array([[-0.00601095,  0.00601095],\n",
            "       [-0.00601095,  0.00601095],\n",
            "       [-0.00601095,  0.00601095],\n",
            "       [-0.00601095,  0.00601095],\n",
            "       [-0.01202091,  0.01202091]])]\n",
            "NEW UPDATED WEIGHTS\n",
            " [array([[-3.78282414e-05, -3.78282414e-05, -3.78282414e-05,\n",
            "        -3.78282414e-05],\n",
            "       [ 1.53690707e-04,  1.53690707e-04,  1.53690707e-04,\n",
            "         1.53690707e-04],\n",
            "       [ 2.25490078e-04,  2.25490078e-04,  2.25490078e-04,\n",
            "         2.25490078e-04]]), array([[-0.02452303,  0.02452303],\n",
            "       [-0.02452303,  0.02452303],\n",
            "       [-0.02452303,  0.02452303],\n",
            "       [-0.02452303,  0.02452303],\n",
            "       [-0.04904475,  0.04904475]])]\n",
            "\n",
            "\n",
            "FORWARD-FEED:\n",
            "Training Instance data:\n",
            " [-0.1  0.1  1. ]\n",
            "Zs:\n",
            " [array([0.50006116, 0.50006116, 0.50006116, 0.50006116, 1.        ]), array([0.47549545, 0.52450455])]\n",
            "\n",
            "BACK-PROPAGATE:\n",
            "COMPUTING ERROR AT OUTPUT NODES\n",
            "CHANGE IN WEIGHTS BETWEEN LAYER 1 AND LAYER 2\n",
            "COMPUTING ERROR AT HIDDEN LAYER NODES\n",
            "PREVIOUS WEIGHTS\n",
            " [array([[-3.78282414e-05, -3.78282414e-05, -3.78282414e-05,\n",
            "        -3.78282414e-05],\n",
            "       [ 1.53690707e-04,  1.53690707e-04,  1.53690707e-04,\n",
            "         1.53690707e-04],\n",
            "       [ 2.25490078e-04,  2.25490078e-04,  2.25490078e-04,\n",
            "         2.25490078e-04]]), array([[-0.02452303,  0.02452303],\n",
            "       [-0.02452303,  0.02452303],\n",
            "       [-0.02452303,  0.02452303],\n",
            "       [-0.02452303,  0.02452303],\n",
            "       [-0.04904475,  0.04904475]])]\n",
            "NODE ERRORS BY LAYER\n",
            " [array([-0.00160394, -0.00160394, -0.00160394, -0.00160394]), array([ 0.13081119, -0.13081119])]\n",
            "CHANGE IN WEIGHTS\n",
            " [array([[ 1.603943e-05,  1.603943e-05,  1.603943e-05,  1.603943e-05],\n",
            "       [-1.603943e-05, -1.603943e-05, -1.603943e-05, -1.603943e-05],\n",
            "       [-1.603943e-04, -1.603943e-04, -1.603943e-04, -1.603943e-04]]), array([[ 0.00654136, -0.00654136],\n",
            "       [ 0.00654136, -0.00654136],\n",
            "       [ 0.00654136, -0.00654136],\n",
            "       [ 0.00654136, -0.00654136],\n",
            "       [ 0.01308112, -0.01308112]])]\n",
            "NEW UPDATED WEIGHTS\n",
            " [array([[-2.17888115e-05, -2.17888115e-05, -2.17888115e-05,\n",
            "        -2.17888115e-05],\n",
            "       [ 1.37651277e-04,  1.37651277e-04,  1.37651277e-04,\n",
            "         1.37651277e-04],\n",
            "       [ 6.50957780e-05,  6.50957780e-05,  6.50957780e-05,\n",
            "         6.50957780e-05]]), array([[-0.01798167,  0.01798167],\n",
            "       [-0.01798167,  0.01798167],\n",
            "       [-0.01798167,  0.01798167],\n",
            "       [-0.01798167,  0.01798167],\n",
            "       [-0.03596363,  0.03596363]])]\n",
            "\n",
            "\n",
            "FORWARD-FEED:\n",
            "Training Instance data:\n",
            " [ 0.  -0.2  1. ]\n",
            "Zs:\n",
            " [array([0.50000939, 0.50000939, 0.50000939, 0.50000939, 1.        ]), array([0.48202584, 0.51797416])]\n",
            "\n",
            "BACK-PROPAGATE:\n",
            "COMPUTING ERROR AT OUTPUT NODES\n",
            "CHANGE IN WEIGHTS BETWEEN LAYER 1 AND LAYER 2\n",
            "COMPUTING ERROR AT HIDDEN LAYER NODES\n",
            "PREVIOUS WEIGHTS\n",
            " [array([[-2.17888115e-05, -2.17888115e-05, -2.17888115e-05,\n",
            "        -2.17888115e-05],\n",
            "       [ 1.37651277e-04,  1.37651277e-04,  1.37651277e-04,\n",
            "         1.37651277e-04],\n",
            "       [ 6.50957780e-05,  6.50957780e-05,  6.50957780e-05,\n",
            "         6.50957780e-05]]), array([[-0.01798167,  0.01798167],\n",
            "       [-0.01798167,  0.01798167],\n",
            "       [-0.01798167,  0.01798167],\n",
            "       [-0.01798167,  0.01798167],\n",
            "       [-0.03596363,  0.03596363]])]\n",
            "NODE ERRORS BY LAYER\n",
            " [array([-0.00116275, -0.00116275, -0.00116275, -0.00116275]), array([ 0.1293262, -0.1293262])]\n",
            "CHANGE IN WEIGHTS\n",
            " [array([[-0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
            "        -0.00000000e+00],\n",
            "       [ 2.32550047e-05,  2.32550047e-05,  2.32550047e-05,\n",
            "         2.32550047e-05],\n",
            "       [-1.16275023e-04, -1.16275023e-04, -1.16275023e-04,\n",
            "        -1.16275023e-04]]), array([[ 0.00646643, -0.00646643],\n",
            "       [ 0.00646643, -0.00646643],\n",
            "       [ 0.00646643, -0.00646643],\n",
            "       [ 0.00646643, -0.00646643],\n",
            "       [ 0.01293262, -0.01293262]])]\n",
            "NEW UPDATED WEIGHTS\n",
            " [array([[-2.17888115e-05, -2.17888115e-05, -2.17888115e-05,\n",
            "        -2.17888115e-05],\n",
            "       [ 1.60906282e-04,  1.60906282e-04,  1.60906282e-04,\n",
            "         1.60906282e-04],\n",
            "       [-5.11792454e-05, -5.11792454e-05, -5.11792454e-05,\n",
            "        -5.11792454e-05]]), array([[-0.01151523,  0.01151523],\n",
            "       [-0.01151523,  0.01151523],\n",
            "       [-0.01151523,  0.01151523],\n",
            "       [-0.01151523,  0.01151523],\n",
            "       [-0.02303101,  0.02303101]])]\n",
            "\n",
            "\n",
            "FORWARD-FEED:\n",
            "Training Instance data:\n",
            " [0.1 0.2 1. ]\n",
            "Zs:\n",
            " [array([0.49999471, 0.49999471, 0.49999471, 0.49999471, 1.        ]), array([0.48848673, 0.51151327])]\n",
            "\n",
            "BACK-PROPAGATE:\n",
            "COMPUTING ERROR AT OUTPUT NODES\n",
            "CHANGE IN WEIGHTS BETWEEN LAYER 1 AND LAYER 2\n",
            "COMPUTING ERROR AT HIDDEN LAYER NODES\n",
            "PREVIOUS WEIGHTS\n",
            " [array([[-2.17888115e-05, -2.17888115e-05, -2.17888115e-05,\n",
            "        -2.17888115e-05],\n",
            "       [ 1.60906282e-04,  1.60906282e-04,  1.60906282e-04,\n",
            "         1.60906282e-04],\n",
            "       [-5.11792454e-05, -5.11792454e-05, -5.11792454e-05,\n",
            "        -5.11792454e-05]]), array([[-0.01151523,  0.01151523],\n",
            "       [-0.01151523,  0.01151523],\n",
            "       [-0.01151523,  0.01151523],\n",
            "       [-0.01151523,  0.01151523],\n",
            "       [-0.02303101,  0.02303101]])]\n",
            "NODE ERRORS BY LAYER\n",
            " [array([-0.00073588, -0.00073588, -0.00073588, -0.00073588]), array([ 0.12781051, -0.12781051])]\n",
            "CHANGE IN WEIGHTS\n",
            " [array([[-7.35884016e-06, -7.35884016e-06, -7.35884016e-06,\n",
            "        -7.35884016e-06],\n",
            "       [-1.47176803e-05, -1.47176803e-05, -1.47176803e-05,\n",
            "        -1.47176803e-05],\n",
            "       [-7.35884016e-05, -7.35884016e-05, -7.35884016e-05,\n",
            "        -7.35884016e-05]]), array([[ 0.00639046, -0.00639046],\n",
            "       [ 0.00639046, -0.00639046],\n",
            "       [ 0.00639046, -0.00639046],\n",
            "       [ 0.00639046, -0.00639046],\n",
            "       [ 0.01278105, -0.01278105]])]\n",
            "NEW UPDATED WEIGHTS\n",
            " [array([[-2.91476516e-05, -2.91476516e-05, -2.91476516e-05,\n",
            "        -2.91476516e-05],\n",
            "       [ 1.46188602e-04,  1.46188602e-04,  1.46188602e-04,\n",
            "         1.46188602e-04],\n",
            "       [-1.24767647e-04, -1.24767647e-04, -1.24767647e-04,\n",
            "        -1.24767647e-04]]), array([[-0.00512478,  0.00512478],\n",
            "       [-0.00512478,  0.00512478],\n",
            "       [-0.00512478,  0.00512478],\n",
            "       [-0.00512478,  0.00512478],\n",
            "       [-0.01024996,  0.01024996]])]\n",
            "\n",
            "\n",
            "FORWARD-FEED:\n",
            "Training Instance data:\n",
            " [ 0.2 -0.2  1. ]\n",
            "Zs:\n",
            " [array([0.49996004, 0.49996004, 0.49996004, 0.49996004, 1.        ]), array([0.49487551, 0.50512449])]\n",
            "\n",
            "BACK-PROPAGATE:\n",
            "COMPUTING ERROR AT OUTPUT NODES\n",
            "CHANGE IN WEIGHTS BETWEEN LAYER 1 AND LAYER 2\n",
            "COMPUTING ERROR AT HIDDEN LAYER NODES\n",
            "PREVIOUS WEIGHTS\n",
            " [array([[-2.91476516e-05, -2.91476516e-05, -2.91476516e-05,\n",
            "        -2.91476516e-05],\n",
            "       [ 1.46188602e-04,  1.46188602e-04,  1.46188602e-04,\n",
            "         1.46188602e-04],\n",
            "       [-1.24767647e-04, -1.24767647e-04, -1.24767647e-04,\n",
            "        -1.24767647e-04]]), array([[-0.00512478,  0.00512478],\n",
            "       [-0.00512478,  0.00512478],\n",
            "       [-0.00512478,  0.00512478],\n",
            "       [-0.00512478,  0.00512478],\n",
            "       [-0.01024996,  0.01024996]])]\n",
            "NODE ERRORS BY LAYER\n",
            " [array([-0.00032355, -0.00032355, -0.00032355, -0.00032355]), array([ 0.12626786, -0.12626786])]\n",
            "CHANGE IN WEIGHTS\n",
            " [array([[-6.47094528e-06, -6.47094528e-06, -6.47094528e-06,\n",
            "        -6.47094528e-06],\n",
            "       [ 6.47094528e-06,  6.47094528e-06,  6.47094528e-06,\n",
            "         6.47094528e-06],\n",
            "       [-3.23547264e-05, -3.23547264e-05, -3.23547264e-05,\n",
            "        -3.23547264e-05]]), array([[ 0.00631289, -0.00631289],\n",
            "       [ 0.00631289, -0.00631289],\n",
            "       [ 0.00631289, -0.00631289],\n",
            "       [ 0.00631289, -0.00631289],\n",
            "       [ 0.01262679, -0.01262679]])]\n",
            "NEW UPDATED WEIGHTS\n",
            " [array([[-3.56185969e-05, -3.56185969e-05, -3.56185969e-05,\n",
            "        -3.56185969e-05],\n",
            "       [ 1.52659547e-04,  1.52659547e-04,  1.52659547e-04,\n",
            "         1.52659547e-04],\n",
            "       [-1.57122373e-04, -1.57122373e-04, -1.57122373e-04,\n",
            "        -1.57122373e-04]]), array([[ 0.00118811, -0.00118811],\n",
            "       [ 0.00118811, -0.00118811],\n",
            "       [ 0.00118811, -0.00118811],\n",
            "       [ 0.00118811, -0.00118811],\n",
            "       [ 0.00237682, -0.00237682]])]\n",
            "\n",
            "\n",
            "FORWARD-FEED:\n",
            "Training Instance data:\n",
            " [-0.4  0.3  1. ]\n",
            "Zs:\n",
            " [array([0.49997573, 0.49997573, 0.49997573, 0.49997573, 1.        ]), array([0.50118823, 0.49881177])]\n",
            "\n",
            "BACK-PROPAGATE:\n",
            "COMPUTING ERROR AT OUTPUT NODES\n",
            "CHANGE IN WEIGHTS BETWEEN LAYER 1 AND LAYER 2\n",
            "COMPUTING ERROR AT HIDDEN LAYER NODES\n",
            "PREVIOUS WEIGHTS\n",
            " [array([[-3.56185969e-05, -3.56185969e-05, -3.56185969e-05,\n",
            "        -3.56185969e-05],\n",
            "       [ 1.52659547e-04,  1.52659547e-04,  1.52659547e-04,\n",
            "         1.52659547e-04],\n",
            "       [-1.57122373e-04, -1.57122373e-04, -1.57122373e-04,\n",
            "        -1.57122373e-04]]), array([[ 0.00118811, -0.00118811],\n",
            "       [ 0.00118811, -0.00118811],\n",
            "       [ 0.00118811, -0.00118811],\n",
            "       [ 0.00118811, -0.00118811],\n",
            "       [ 0.00237682, -0.00237682]])]\n",
            "NODE ERRORS BY LAYER\n",
            " [array([-7.44330532e-05, -7.44330532e-05, -7.44330532e-05, -7.44330532e-05]), array([-0.12529635,  0.12529635])]\n",
            "CHANGE IN WEIGHTS\n",
            " [array([[ 2.97732213e-06,  2.97732213e-06,  2.97732213e-06,\n",
            "         2.97732213e-06],\n",
            "       [-2.23299160e-06, -2.23299160e-06, -2.23299160e-06,\n",
            "        -2.23299160e-06],\n",
            "       [-7.44330532e-06, -7.44330532e-06, -7.44330532e-06,\n",
            "        -7.44330532e-06]]), array([[-0.00626451,  0.00626451],\n",
            "       [-0.00626451,  0.00626451],\n",
            "       [-0.00626451,  0.00626451],\n",
            "       [-0.00626451,  0.00626451],\n",
            "       [-0.01252964,  0.01252964]])]\n",
            "NEW UPDATED WEIGHTS\n",
            " [array([[-3.26412748e-05, -3.26412748e-05, -3.26412748e-05,\n",
            "        -3.26412748e-05],\n",
            "       [ 1.50426555e-04,  1.50426555e-04,  1.50426555e-04,\n",
            "         1.50426555e-04],\n",
            "       [-1.64565679e-04, -1.64565679e-04, -1.64565679e-04,\n",
            "        -1.64565679e-04]]), array([[-0.0050764 ,  0.0050764 ],\n",
            "       [-0.0050764 ,  0.0050764 ],\n",
            "       [-0.0050764 ,  0.0050764 ],\n",
            "       [-0.0050764 ,  0.0050764 ],\n",
            "       [-0.01015281,  0.01015281]])]\n",
            "\n",
            "\n",
            "FORWARD-FEED:\n",
            "Training Instance data:\n",
            " [-0.3  0.8  1. ]\n",
            "Zs:\n",
            " [array([0.49999139, 0.49999139, 0.49999139, 0.49999139, 1.        ]), array([0.49492381, 0.50507619])]\n",
            "\n",
            "BACK-PROPAGATE:\n",
            "COMPUTING ERROR AT OUTPUT NODES\n",
            "CHANGE IN WEIGHTS BETWEEN LAYER 1 AND LAYER 2\n",
            "COMPUTING ERROR AT HIDDEN LAYER NODES\n",
            "PREVIOUS WEIGHTS\n",
            " [array([[-3.26412748e-05, -3.26412748e-05, -3.26412748e-05,\n",
            "        -3.26412748e-05],\n",
            "       [ 1.50426555e-04,  1.50426555e-04,  1.50426555e-04,\n",
            "         1.50426555e-04],\n",
            "       [-1.64565679e-04, -1.64565679e-04, -1.64565679e-04,\n",
            "        -1.64565679e-04]]), array([[-0.0050764 ,  0.0050764 ],\n",
            "       [-0.0050764 ,  0.0050764 ],\n",
            "       [-0.0050764 ,  0.0050764 ],\n",
            "       [-0.0050764 ,  0.0050764 ],\n",
            "       [-0.01015281,  0.01015281]])]\n",
            "NODE ERRORS BY LAYER\n",
            " [array([0.00031402, 0.00031402, 0.00031402, 0.00031402]), array([-0.1237182,  0.1237182])]\n",
            "CHANGE IN WEIGHTS\n",
            " [array([[-9.42064859e-06, -9.42064859e-06, -9.42064859e-06,\n",
            "        -9.42064859e-06],\n",
            "       [ 2.51217296e-05,  2.51217296e-05,  2.51217296e-05,\n",
            "         2.51217296e-05],\n",
            "       [ 3.14021620e-05,  3.14021620e-05,  3.14021620e-05,\n",
            "         3.14021620e-05]]), array([[-0.0061858 ,  0.0061858 ],\n",
            "       [-0.0061858 ,  0.0061858 ],\n",
            "       [-0.0061858 ,  0.0061858 ],\n",
            "       [-0.0061858 ,  0.0061858 ],\n",
            "       [-0.01237182,  0.01237182]])]\n",
            "NEW UPDATED WEIGHTS\n",
            " [array([[-4.20619234e-05, -4.20619234e-05, -4.20619234e-05,\n",
            "        -4.20619234e-05],\n",
            "       [ 1.75548285e-04,  1.75548285e-04,  1.75548285e-04,\n",
            "         1.75548285e-04],\n",
            "       [-1.33163517e-04, -1.33163517e-04, -1.33163517e-04,\n",
            "        -1.33163517e-04]]), array([[-0.0112622 ,  0.0112622 ],\n",
            "       [-0.0112622 ,  0.0112622 ],\n",
            "       [-0.0112622 ,  0.0112622 ],\n",
            "       [-0.0112622 ,  0.0112622 ],\n",
            "       [-0.02252463,  0.02252463]])]\n",
            "\n",
            "\n",
            "FORWARD-FEED:\n",
            "Training Instance data:\n",
            " [-0.2  0.3  1. ]\n",
            "Zs:\n",
            " [array([0.49998198, 0.49998198, 0.49998198, 0.49998198, 1.        ]), array([0.48873985, 0.51126015])]\n",
            "\n",
            "BACK-PROPAGATE:\n",
            "COMPUTING ERROR AT OUTPUT NODES\n",
            "CHANGE IN WEIGHTS BETWEEN LAYER 1 AND LAYER 2\n",
            "COMPUTING ERROR AT HIDDEN LAYER NODES\n",
            "PREVIOUS WEIGHTS\n",
            " [array([[-4.20619234e-05, -4.20619234e-05, -4.20619234e-05,\n",
            "        -4.20619234e-05],\n",
            "       [ 1.75548285e-04,  1.75548285e-04,  1.75548285e-04,\n",
            "         1.75548285e-04],\n",
            "       [-1.33163517e-04, -1.33163517e-04, -1.33163517e-04,\n",
            "        -1.33163517e-04]]), array([[-0.0112622 ,  0.0112622 ],\n",
            "       [-0.0112622 ,  0.0112622 ],\n",
            "       [-0.0112622 ,  0.0112622 ],\n",
            "       [-0.0112622 ,  0.0112622 ],\n",
            "       [-0.02252463,  0.02252463]])]\n",
            "NODE ERRORS BY LAYER\n",
            " [array([0.00068769, 0.00068769, 0.00068769, 0.00068769]), array([-0.12212299,  0.12212299])]\n",
            "CHANGE IN WEIGHTS\n",
            " [array([[-1.37537417e-05, -1.37537417e-05, -1.37537417e-05,\n",
            "        -1.37537417e-05],\n",
            "       [ 2.06306126e-05,  2.06306126e-05,  2.06306126e-05,\n",
            "         2.06306126e-05],\n",
            "       [ 6.87687087e-05,  6.87687087e-05,  6.87687087e-05,\n",
            "         6.87687087e-05]]), array([[-0.00610593,  0.00610593],\n",
            "       [-0.00610593,  0.00610593],\n",
            "       [-0.00610593,  0.00610593],\n",
            "       [-0.00610593,  0.00610593],\n",
            "       [-0.0122123 ,  0.0122123 ]])]\n",
            "NEW UPDATED WEIGHTS\n",
            " [array([[-5.58156651e-05, -5.58156651e-05, -5.58156651e-05,\n",
            "        -5.58156651e-05],\n",
            "       [ 1.96178897e-04,  1.96178897e-04,  1.96178897e-04,\n",
            "         1.96178897e-04],\n",
            "       [-6.43948081e-05, -6.43948081e-05, -6.43948081e-05,\n",
            "        -6.43948081e-05]]), array([[-0.01736813,  0.01736813],\n",
            "       [-0.01736813,  0.01736813],\n",
            "       [-0.01736813,  0.01736813],\n",
            "       [-0.01736813,  0.01736813],\n",
            "       [-0.03473693,  0.03473693]])]\n",
            "\n",
            "\n",
            "FORWARD-FEED:\n",
            "Training Instance data:\n",
            " [-0.1  0.9  1. ]\n",
            "Zs:\n",
            " [array([0.50002944, 0.50002944, 0.50002944, 0.50002944, 1.        ]), array([0.48263817, 0.51736183])]\n",
            "\n",
            "BACK-PROPAGATE:\n",
            "COMPUTING ERROR AT OUTPUT NODES\n",
            "CHANGE IN WEIGHTS BETWEEN LAYER 1 AND LAYER 2\n",
            "COMPUTING ERROR AT HIDDEN LAYER NODES\n",
            "PREVIOUS WEIGHTS\n",
            " [array([[-5.58156651e-05, -5.58156651e-05, -5.58156651e-05,\n",
            "        -5.58156651e-05],\n",
            "       [ 1.96178897e-04,  1.96178897e-04,  1.96178897e-04,\n",
            "         1.96178897e-04],\n",
            "       [-6.43948081e-05, -6.43948081e-05, -6.43948081e-05,\n",
            "        -6.43948081e-05]]), array([[-0.01736813,  0.01736813],\n",
            "       [-0.01736813,  0.01736813],\n",
            "       [-0.01736813,  0.01736813],\n",
            "       [-0.01736813,  0.01736813],\n",
            "       [-0.03473693,  0.03473693]])]\n",
            "NODE ERRORS BY LAYER\n",
            " [array([0.00104655, 0.00104655, 0.00104655, 0.00104655]), array([-0.12051406,  0.12051406])]\n",
            "CHANGE IN WEIGHTS\n",
            " [array([[-1.04655220e-05, -1.04655220e-05, -1.04655220e-05,\n",
            "        -1.04655220e-05],\n",
            "       [ 9.41896976e-05,  9.41896976e-05,  9.41896976e-05,\n",
            "         9.41896976e-05],\n",
            "       [ 1.04655220e-04,  1.04655220e-04,  1.04655220e-04,\n",
            "         1.04655220e-04]]), array([[-0.00602606,  0.00602606],\n",
            "       [-0.00602606,  0.00602606],\n",
            "       [-0.00602606,  0.00602606],\n",
            "       [-0.00602606,  0.00602606],\n",
            "       [-0.01205141,  0.01205141]])]\n",
            "NEW UPDATED WEIGHTS\n",
            " [array([[-6.62811871e-05, -6.62811871e-05, -6.62811871e-05,\n",
            "        -6.62811871e-05],\n",
            "       [ 2.90368595e-04,  2.90368595e-04,  2.90368595e-04,\n",
            "         2.90368595e-04],\n",
            "       [ 4.02604114e-05,  4.02604114e-05,  4.02604114e-05,\n",
            "         4.02604114e-05]]), array([[-0.02339419,  0.02339419],\n",
            "       [-0.02339419,  0.02339419],\n",
            "       [-0.02339419,  0.02339419],\n",
            "       [-0.02339419,  0.02339419],\n",
            "       [-0.04678834,  0.04678834]])]\n",
            "\n",
            "\n",
            "FORWARD-FEED:\n",
            "Training Instance data:\n",
            " [-0.1  0.1  1. ]\n",
            "Zs:\n",
            " [array([0.50001898, 0.50001898, 0.50001898, 0.50001898, 1.        ]), array([0.47662243, 0.52337757])]\n",
            "\n",
            "BACK-PROPAGATE:\n",
            "COMPUTING ERROR AT OUTPUT NODES\n",
            "CHANGE IN WEIGHTS BETWEEN LAYER 1 AND LAYER 2\n",
            "COMPUTING ERROR AT HIDDEN LAYER NODES\n",
            "PREVIOUS WEIGHTS\n",
            " [array([[-6.62811871e-05, -6.62811871e-05, -6.62811871e-05,\n",
            "        -6.62811871e-05],\n",
            "       [ 2.90368595e-04,  2.90368595e-04,  2.90368595e-04,\n",
            "         2.90368595e-04],\n",
            "       [ 4.02604114e-05,  4.02604114e-05,  4.02604114e-05,\n",
            "         4.02604114e-05]]), array([[-0.02339419,  0.02339419],\n",
            "       [-0.02339419,  0.02339419],\n",
            "       [-0.02339419,  0.02339419],\n",
            "       [-0.02339419,  0.02339419],\n",
            "       [-0.04678834,  0.04678834]])]\n",
            "NODE ERRORS BY LAYER\n",
            " [array([-0.00152715, -0.00152715, -0.00152715, -0.00152715]), array([ 0.13055836, -0.13055836])]\n",
            "CHANGE IN WEIGHTS\n",
            " [array([[ 1.52715369e-05,  1.52715369e-05,  1.52715369e-05,\n",
            "         1.52715369e-05],\n",
            "       [-1.52715369e-05, -1.52715369e-05, -1.52715369e-05,\n",
            "        -1.52715369e-05],\n",
            "       [-1.52715369e-04, -1.52715369e-04, -1.52715369e-04,\n",
            "        -1.52715369e-04]]), array([[ 0.00652817, -0.00652817],\n",
            "       [ 0.00652817, -0.00652817],\n",
            "       [ 0.00652817, -0.00652817],\n",
            "       [ 0.00652817, -0.00652817],\n",
            "       [ 0.01305584, -0.01305584]])]\n",
            "NEW UPDATED WEIGHTS\n",
            " [array([[-5.10096502e-05, -5.10096502e-05, -5.10096502e-05,\n",
            "        -5.10096502e-05],\n",
            "       [ 2.75097058e-04,  2.75097058e-04,  2.75097058e-04,\n",
            "         2.75097058e-04],\n",
            "       [-1.12454957e-04, -1.12454957e-04, -1.12454957e-04,\n",
            "        -1.12454957e-04]]), array([[-0.01686603,  0.01686603],\n",
            "       [-0.01686603,  0.01686603],\n",
            "       [-0.01686603,  0.01686603],\n",
            "       [-0.01686603,  0.01686603],\n",
            "       [-0.0337325 ,  0.0337325 ]])]\n",
            "\n",
            "\n",
            "FORWARD-FEED:\n",
            "Training Instance data:\n",
            " [ 0.  -0.2  1. ]\n",
            "Zs:\n",
            " [array([0.49995813, 0.49995813, 0.49995813, 0.49995813, 1.        ]), array([0.48314096, 0.51685904])]\n",
            "\n",
            "BACK-PROPAGATE:\n",
            "COMPUTING ERROR AT OUTPUT NODES\n",
            "CHANGE IN WEIGHTS BETWEEN LAYER 1 AND LAYER 2\n",
            "COMPUTING ERROR AT HIDDEN LAYER NODES\n",
            "PREVIOUS WEIGHTS\n",
            " [array([[-5.10096502e-05, -5.10096502e-05, -5.10096502e-05,\n",
            "        -5.10096502e-05],\n",
            "       [ 2.75097058e-04,  2.75097058e-04,  2.75097058e-04,\n",
            "         2.75097058e-04],\n",
            "       [-1.12454957e-04, -1.12454957e-04, -1.12454957e-04,\n",
            "        -1.12454957e-04]]), array([[-0.01686603,  0.01686603],\n",
            "       [-0.01686603,  0.01686603],\n",
            "       [-0.01686603,  0.01686603],\n",
            "       [-0.01686603,  0.01686603],\n",
            "       [-0.0337325 ,  0.0337325 ]])]\n",
            "NODE ERRORS BY LAYER\n",
            " [array([-0.00108843, -0.00108843, -0.00108843, -0.00108843]), array([ 0.12906785, -0.12906785])]\n",
            "CHANGE IN WEIGHTS\n",
            " [array([[-0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
            "        -0.00000000e+00],\n",
            "       [ 2.17686182e-05,  2.17686182e-05,  2.17686182e-05,\n",
            "         2.17686182e-05],\n",
            "       [-1.08843091e-04, -1.08843091e-04, -1.08843091e-04,\n",
            "        -1.08843091e-04]]), array([[ 0.00645285, -0.00645285],\n",
            "       [ 0.00645285, -0.00645285],\n",
            "       [ 0.00645285, -0.00645285],\n",
            "       [ 0.00645285, -0.00645285],\n",
            "       [ 0.01290679, -0.01290679]])]\n",
            "NEW UPDATED WEIGHTS\n",
            " [array([[-5.10096502e-05, -5.10096502e-05, -5.10096502e-05,\n",
            "        -5.10096502e-05],\n",
            "       [ 2.96865676e-04,  2.96865676e-04,  2.96865676e-04,\n",
            "         2.96865676e-04],\n",
            "       [-2.21298048e-04, -2.21298048e-04, -2.21298048e-04,\n",
            "        -2.21298048e-04]]), array([[-0.01041317,  0.01041317],\n",
            "       [-0.01041317,  0.01041317],\n",
            "       [-0.01041317,  0.01041317],\n",
            "       [-0.01041317,  0.01041317],\n",
            "       [-0.02082572,  0.02082572]])]\n",
            "\n",
            "\n",
            "FORWARD-FEED:\n",
            "Training Instance data:\n",
            " [0.1 0.2 1. ]\n",
            "Zs:\n",
            " [array([0.49995824, 0.49995824, 0.49995824, 0.49995824, 1.        ]), array([0.48958892, 0.51041108])]\n",
            "\n",
            "BACK-PROPAGATE:\n",
            "COMPUTING ERROR AT OUTPUT NODES\n",
            "CHANGE IN WEIGHTS BETWEEN LAYER 1 AND LAYER 2\n",
            "COMPUTING ERROR AT HIDDEN LAYER NODES\n",
            "PREVIOUS WEIGHTS\n",
            " [array([[-5.10096502e-05, -5.10096502e-05, -5.10096502e-05,\n",
            "        -5.10096502e-05],\n",
            "       [ 2.96865676e-04,  2.96865676e-04,  2.96865676e-04,\n",
            "         2.96865676e-04],\n",
            "       [-2.21298048e-04, -2.21298048e-04, -2.21298048e-04,\n",
            "        -2.21298048e-04]]), array([[-0.01041317,  0.01041317],\n",
            "       [-0.01041317,  0.01041317],\n",
            "       [-0.01041317,  0.01041317],\n",
            "       [-0.01041317,  0.01041317],\n",
            "       [-0.02082572,  0.02082572]])]\n",
            "NODE ERRORS BY LAYER\n",
            " [array([-0.00066409, -0.00066409, -0.00066409, -0.00066409]), array([ 0.12754745, -0.12754745])]\n",
            "CHANGE IN WEIGHTS\n",
            " [array([[-6.64086870e-06, -6.64086870e-06, -6.64086870e-06,\n",
            "        -6.64086870e-06],\n",
            "       [-1.32817374e-05, -1.32817374e-05, -1.32817374e-05,\n",
            "        -1.32817374e-05],\n",
            "       [-6.64086870e-05, -6.64086870e-05, -6.64086870e-05,\n",
            "        -6.64086870e-05]]), array([[ 0.00637684, -0.00637684],\n",
            "       [ 0.00637684, -0.00637684],\n",
            "       [ 0.00637684, -0.00637684],\n",
            "       [ 0.00637684, -0.00637684],\n",
            "       [ 0.01275474, -0.01275474]])]\n",
            "NEW UPDATED WEIGHTS\n",
            " [array([[-5.76505189e-05, -5.76505189e-05, -5.76505189e-05,\n",
            "        -5.76505189e-05],\n",
            "       [ 2.83583939e-04,  2.83583939e-04,  2.83583939e-04,\n",
            "         2.83583939e-04],\n",
            "       [-2.87706735e-04, -2.87706735e-04, -2.87706735e-04,\n",
            "        -2.87706735e-04]]), array([[-0.00403633,  0.00403633],\n",
            "       [-0.00403633,  0.00403633],\n",
            "       [-0.00403633,  0.00403633],\n",
            "       [-0.00403633,  0.00403633],\n",
            "       [-0.00807097,  0.00807097]])]\n",
            "\n",
            "\n",
            "FORWARD-FEED:\n",
            "Training Instance data:\n",
            " [ 0.2 -0.2  1. ]\n",
            "Zs:\n",
            " [array([0.49991101, 0.49991101, 0.49991101, 0.49991101, 1.        ]), array([0.49596454, 0.50403546])]\n",
            "\n",
            "BACK-PROPAGATE:\n",
            "COMPUTING ERROR AT OUTPUT NODES\n",
            "CHANGE IN WEIGHTS BETWEEN LAYER 1 AND LAYER 2\n",
            "COMPUTING ERROR AT HIDDEN LAYER NODES\n",
            "PREVIOUS WEIGHTS\n",
            " [array([[-5.76505189e-05, -5.76505189e-05, -5.76505189e-05,\n",
            "        -5.76505189e-05],\n",
            "       [ 2.83583939e-04,  2.83583939e-04,  2.83583939e-04,\n",
            "         2.83583939e-04],\n",
            "       [-2.87706735e-04, -2.87706735e-04, -2.87706735e-04,\n",
            "        -2.87706735e-04]]), array([[-0.00403633,  0.00403633],\n",
            "       [-0.00403633,  0.00403633],\n",
            "       [-0.00403633,  0.00403633],\n",
            "       [-0.00403633,  0.00403633],\n",
            "       [-0.00807097,  0.00807097]])]\n",
            "NODE ERRORS BY LAYER\n",
            " [array([-0.00025429, -0.00025429, -0.00025429, -0.00025429]), array([ 0.12600066, -0.12600066])]\n",
            "CHANGE IN WEIGHTS\n",
            " [array([[-5.08580771e-06, -5.08580771e-06, -5.08580771e-06,\n",
            "        -5.08580771e-06],\n",
            "       [ 5.08580771e-06,  5.08580771e-06,  5.08580771e-06,\n",
            "         5.08580771e-06],\n",
            "       [-2.54290386e-05, -2.54290386e-05, -2.54290386e-05,\n",
            "        -2.54290386e-05]]), array([[ 0.00629891, -0.00629891],\n",
            "       [ 0.00629891, -0.00629891],\n",
            "       [ 0.00629891, -0.00629891],\n",
            "       [ 0.00629891, -0.00629891],\n",
            "       [ 0.01260007, -0.01260007]])]\n",
            "NEW UPDATED WEIGHTS\n",
            " [array([[-6.27363266e-05, -6.27363266e-05, -6.27363266e-05,\n",
            "        -6.27363266e-05],\n",
            "       [ 2.88669747e-04,  2.88669747e-04,  2.88669747e-04,\n",
            "         2.88669747e-04],\n",
            "       [-3.13135774e-04, -3.13135774e-04, -3.13135774e-04,\n",
            "        -3.13135774e-04]]), array([[ 0.00226258, -0.00226258],\n",
            "       [ 0.00226258, -0.00226258],\n",
            "       [ 0.00226258, -0.00226258],\n",
            "       [ 0.00226258, -0.00226258],\n",
            "       [ 0.00452909, -0.00452909]])]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLP(arch=[2, 4, 2], epochs=2)"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ],
      "source": [
        "from scipy.io.arff import loadarff \n",
        "import pandas as pd\n",
        "# Load debug data\n",
        "\n",
        "# Train on debug data\n",
        "\n",
        "# Print weights\n",
        "\n",
        "\n",
        "# LOAD DEBUG DATA\n",
        "raw_data = loadarff('/content/drive/MyDrive/School/CS_472_MachLearning/labs/lab2_backpropagation/data/linsep2nonorigin.arff')\n",
        "df_data = pd.DataFrame(raw_data[0])\n",
        "\n",
        "# CHANGE THE VALUES OF THE ROWS OF THE 'class' COLUMN TO BE 1s AND 0s INSTEAD OF \"b'1'\" OR \"b'0'\"\n",
        "df_data['class'] = df_data['class'].astype(int) \n",
        "\n",
        "np_arr = df_data.to_numpy() #cast dataframe to numpy array\n",
        "# np_arr = np.array([[-1,0.4,0.2]])\n",
        "# np_arr = np.array([[.9,.6,0]])\n",
        "cutoff = np_arr.shape[1] - 1 #the index to split the X and y arrays\n",
        "\n",
        "# CUT THE numpy array INTO AN X AND y ARRAY\n",
        "X = np_arr[:,:cutoff] #inputs: from 1st column to cutoff (exclusive)\n",
        "y_2D = np_arr[:,cutoff:] #targets: from cutoff to last column\n",
        "\n",
        "# SET INITIAL WEIGHTS TO ZERO\n",
        "wts = np.zeros((X.shape[1]+1,1)) # weights\n",
        "\n",
        "# TRAIN ON DEBUG DATA\n",
        "mlp = MLP([2,4,2],2,0.1,0)\n",
        "mlp.fit(X,y_2D,epochs_no_change=11,tol=0.01,default_wts=False,initial_wts=0)\n",
        "\n",
        "\n",
        "\n",
        "# PRINT ACCURACY AND WEIGHTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kY3VNB1ui03N"
      },
      "source": [
        "### 1.1.2 Evaluation\n",
        "\n",
        "Evaluate your model using the following parameters:\n",
        "\n",
        "Learning Rate = 0.1\\\n",
        "Momentum = 0.5\\\n",
        "Deterministic = 10 [This means run it 10 epochs and should be the same everytime you run it]\\\n",
        "Shuffle = False\\\n",
        "Validation size = 0\\\n",
        "Initial Weights = All zeros\\\n",
        "Hidden Layer Widths = [4]\n",
        "\n",
        "We will evaluate your model based on printed weights after training on the [Evaluation Dataset](https://byu.instructure.com/courses/14142/files?preview=4421294)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yAxA78QjDh2"
      },
      "outputs": [],
      "source": [
        "# Load evaluation data\n",
        "\n",
        "# Train on evaluation data\n",
        "\n",
        "# Print weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vWiTdlbR2Xh"
      },
      "source": [
        "## 2. (10%) Backpropagation on the Iris Classification problem.\n",
        "\n",
        "Load the Iris Dataset [Iris Dataset](https://byu.instructure.com/courses/14142/files?preview=4421369)\n",
        "\n",
        "Parameters:\n",
        "- One layer of hidden nodes with the number of hidden nodes being twice the number of inputs.\n",
        "- Use a 80/20 split of the data for the training/test set.\n",
        "- Use a learning rate of 0.1\n",
        "- Use a validation set (15% of the training set) taken from the training set for your stopping criteria\n",
        "- Create one graph with MSE (mean squared error) over epochs from the training set and validation set\n",
        "- Create one graph with classification accuracy (% classified correctly) over epochs from the training set and validation set\n",
        "- Print out your test set accuracy\n",
        "\n",
        "The results for the different measurables should be shown with a different color, line type, etc. Typical backpropagation accuracies for the Iris data set are 85-95%.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SSoasDQSKXb"
      },
      "outputs": [],
      "source": [
        "# Iris Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIRG42TgSR4x"
      },
      "source": [
        "## 3. (10%) Working with the Vowel Dataset - Learning Rate\n",
        "\n",
        "Load the Vowel Dataset [Vowel Dataset](https://byu.instructure.com/courses/14142/files?preview=4537354)\n",
        "\n",
        "- Use one layer of hidden nodes with the number of hidden nodes being twice the number of inputs.\n",
        "- Use random 80/20 splits of the data for the training/test set.\n",
        "- Use a validation set (15% of the training set) taken from the training set for your stopping criteria\n",
        "- Try some different learning rates (LR). Note that each LR will probably require a different number of epochs to learn. \n",
        "\n",
        "- For each LR you test, plot their validation's set MSE over Epochs on the same graph. Graph 4-5 different LRs and make them different enough to see a difference between them.\n",
        "\n",
        "In general, whenever you are testing a parameter such as LR, # of hidden nodes, etc., test values until no more improvement is found. For example, if 20 hidden nodes did better than 10, you would not stop at 20, but would try 40, etc., until you no longer get improvement.\n",
        "\n",
        "If you would like you may average the results of multiple initial conditions (e.g. 3) per LR, and that obviously would give more accurate results.\n",
        "\n",
        "<img src=https://raw.githubusercontent.com/cs472ta/CS472/master/images/backpropagation/backprop_val_set_MSE_vs_epochs.png width=500 height=500  align=\"left\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBGUn43ASiXW"
      },
      "outputs": [],
      "source": [
        "# Train on each dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOteTlV6S0bq"
      },
      "source": [
        "## 3.1 (5%) Working with the Vowel Dataset - Intuition\n",
        "- Discuss the effect of varying learning rates. \n",
        "- Discuss why the vowel data set might be more difficult than Iris\n",
        "    - Report both datasets' baseline accuracies and best **test** set accuracies. \n",
        "- Consider which of the vowel dataset's given input features you should actually use (Train/test, speaker, gender, ect) and discuss why you chose the ones you did.\n",
        "\n",
        "Typical backpropagation accuracies for the Vowel data set are above 75%.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmq9GSbJS8k2"
      },
      "source": [
        "*Discuss Intuition here*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCnyi7wtBTCM"
      },
      "source": [
        "## 3.2 (10%) Working with the Vowel Dataset - Hidden Layer Nodes\n",
        "\n",
        "Using the best LR you discovered, experiment with different numbers of hidden nodes.\n",
        "\n",
        "- Start with 1 hidden node, then 2, and then double them for each test until you get no more improvement in accuracy. \n",
        "- For each number of hidden nodes find the best validation set solution (in terms of validation set MSE).  \n",
        "- Create one graph with MSE for the training set and validation set on the y-axis and # of hidden nodes on the x-axis.\n",
        "- Report the final test set accuracy for every # of hidden nodes you experimented on"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2JTuao6BTCM"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXB_e0-5BTCM"
      },
      "source": [
        "*Discuss Hidden Layer Nodes here*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYuhn1qsBTCM"
      },
      "source": [
        "## 3.3 (10%) Working with the Vowel Dataset - Momentum\n",
        "\n",
        "Try some different momentum terms using the best number of hidden nodes and LR from your earlier experiments.\n",
        "\n",
        "- Create a graph similar to step 3.2, but with momentum on the x-axis and number of epochs until validation set convergence on the y-axis.\n",
        "- For each momentum term, print the test set accuracy. \n",
        "- You are trying to see how much momentum speeds up learning and how it affects accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8hMcc3kBTCN"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEgtEY81BTCN"
      },
      "source": [
        "*Discuss Momentum here*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBBmeNQ7jvcQ"
      },
      "source": [
        "## 4.1 (10%) Use the scikit-learn (SK) version of the MLP classifier on the Iris and Vowel data sets.  \n",
        "\n",
        "You do not need to go through all the steps above, nor graph results. Compare results (accuracy and learning speed) between your version and theirs for some selection of hyper-parameters. Try different hyper-parameters and comment on their effect.\n",
        "\n",
        "At a minimum, try\n",
        "\n",
        "- number of hidden nodes and layers\n",
        "- different activation functions\n",
        "- learning rate\n",
        "- regularization and parameters\n",
        "- momentum (and try nesterov)\n",
        "- early stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFQv70W2VyqJ"
      },
      "outputs": [],
      "source": [
        "# Load sklearn perceptron\n",
        "\n",
        "# Train on voting dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqSFAXwlk3Ms"
      },
      "source": [
        "*Record impressions*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmDm8gnCBTCO"
      },
      "source": [
        "## 4.2 (5%) Using the Iris Dataset automatically adjust hyper-parameters using your choice of grid/random search\n",
        "- Use a grid or random search approach across a reasonable subset of hyper-parameters from the above \n",
        "- Report your best accuracy and hyper-parameters. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAyUtXh0BTCO"
      },
      "outputs": [],
      "source": [
        "# Load sklearn perceptron\n",
        "\n",
        "# Train on voting dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTlK-kijk8Mg"
      },
      "source": [
        "## 5. (Optional 5% Extra credit) For the vowel data set, use the other hyper-parameter approach that you did not use in part 4.2 to find LR, # of hidden nodes, and momentum.  \n",
        "\n",
        "- Compare and discuss the values found with the ones you found in part 3.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9KatPD7BTCP"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ps3oqZdBBTCP"
      },
      "source": [
        "*Discuss findings here*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "lab_2_backprop.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}